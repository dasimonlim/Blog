[
  {
    "path": "posts/2021-04-10-predictive-modelling/",
    "title": "Predictive Modeling of H1N1 Vaccination",
    "description": "The predictive modeling component of the Shiny application allows the user to customize and use different modeling techniques to build a predictive model to predict whether an individual would take the H1N1 vaccine.",
    "author": [
      {
        "name": "Desmond LIM Pek Loong",
        "url": {}
      }
    ],
    "date": "2021-03-23",
    "categories": [],
    "contents": "\r\n\r\nContents\r\n1. Introduction\r\n1.1 Purpose\r\n\r\n2. Data Preparation\r\n2.1 Data Source\r\n2.2 Date Wrangling and Cleaning\r\n\r\n3 Modeling\r\n3.1 Literature Review: Choosing the right Modeling Package\r\n3.2 Data Splitting\r\n3.3 Model Tuning\r\n\r\n4. Plotting Variable Importance\r\n5. Model Comparision by ROC/AUC and Visualisations\r\n5.1 Comparing ROC Packages\r\n5.1.1 Using ROCR Package\r\n5.1.2 Using pROC Package\r\n5.1.3 Using plotROC Package\r\n5.1.4 ROC Package Comparison\r\n\r\n5.2 Obtaining the AUC Table\r\n5.3 Comparing Model Performance via Resampling\r\n\r\n6. Proposed Visualisation from Shiny Module\r\n7. Conclusion/Reflections\r\nReferences\r\n\r\n1. Introduction\r\nWith the ongoing COVID-19 pandemic, the world is experiencing first-hand on how a virus could affect economy, society and the deaths that it could cause. The importance of having a vaccine and having the general population taking the vaccine is key to curbing the spread of the virus and saving lives.\r\nA similar situation was the H1N1 virus pandemic which occurred in 2009, where an estimated amount of 151,700-575,400 people worldwide had died during the first year of the virus. Being able to predict which individuals are likely to receive their H1N1 vaccinations, it will guide governments, health officials to know what are the important predictors that lead them to take the H1N1 vaccine. This understanding would be useful in future efforts to promote vaccination to the public, especially when a vaccine for the current pandemic is made.\r\n1.1 Purpose\r\nThe purpose of the study is to develop various predictive models on the individuals who are likely to take the H1N1 vaccine based on the flu survey data , to be able to assess the models for the optimal model and visualize the assessment.\r\n2. Data Preparation\r\nThe data used was obtained from the United States Centre of Disease Control and Prevention (CDC)’s website https://www.cdc.gov/nchs/nis/data_files_h1n1.htm on the National 2009 H1N1 flu survey conducted in the US.\r\n2.1 Data Source\r\nThe dataset in excel format was imported by read_csv into the RStudio environment. The following code was used to launch the mentioned packages in R.\r\n\r\n\r\n#R packages used to modelling and visualization\r\n\r\npackages = c('tidyverse','readr','caret','caTools','ggpubr','ROCR','pROC','plotROC','plotly')\r\nfor (p in packages){\r\n  if(!require(p, character.only = T)){\r\n  install.packages(p)\r\n  }\r\n  library(p,character.only= T ) \r\n} \r\n\r\n\r\n\r\n\r\n\r\nH1N1 <- read_csv('data/H1N1_Final_dan_edit.csv')\r\n\r\nglimpse(H1N1)\r\n\r\n\r\n\r\nCheck for missing data i.e NA is conducted on the data. Variables with missing data were noted down.\r\n\r\n\r\ncolMeans(is.na(H1N1))\r\n\r\n\r\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \r\n       0.005694632        0.005652346        0.203865020 \r\n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \r\n       0.207910465        0.201976207        0.202765562 \r\n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \r\n       0.203794542        0.203963690        0.205373252 \r\n     CONCERN LEVEL               HQ23               HQ24 \r\n       0.000000000        0.854434484        0.962717073 \r\n            HQ24_B           INT_H1N1           INT_NEXT \r\n       0.994587280        0.000000000        0.000000000 \r\n          INT_SEAS          KNOW_H1N1                Q23 \r\n       0.000000000        0.000000000        0.960165765 \r\n               Q24              Q24_B             DOCREC \r\n       0.977136897        0.996447903        0.000000000 \r\n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \r\n       0.961913622        0.961913622        0.020889716 \r\n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \r\n       0.017083897        0.922488160        1.000000000 \r\n             PSL_2                 Q9             Q9_NUM \r\n       1.000000000        1.000000000        1.000000000 \r\n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \r\n       0.031799729        0.226291159        0.225713239 \r\n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \r\n       0.265195083        0.000000000        0.244009359 \r\n        HH_CHILD_R             HISP_I           INC_CAT1 \r\n       0.007132386        0.000000000        0.214436739 \r\n            INSURE            MARITAL          N_ADULT_R \r\n       1.000000000        0.244544993        0.007132386 \r\n        N_PEOPLE_R                Q95         Q95_INDSTR \r\n       0.003157420        0.994432228        0.595554240 \r\n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \r\n       0.595554240        0.000000000        0.983451737 \r\n             SEX_I              STATE REAS_NOH1N1_AHAD_F \r\n       0.000000000        0.000000000        0.399484100 \r\nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \r\n       0.399484100        0.399484100        0.399484100 \r\nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \r\n       0.399484100        0.399484100        0.399484100 \r\n\r\n2.2 Date Wrangling and Cleaning\r\nBefore the dataset can be used for modelling, the missing data would need to processed.\r\nThe following section focused on wrangling the data set and cleaning up missing variables. The code below is used to remove the missing data from the target variable, VACC_H1N1_F.\r\n\r\n\r\n#exclude the NA column in the target variable\r\nH1N1 <- H1N1 %>%\r\n  filter(!is.na(VACC_H1N1_F))\r\n\r\n\r\n\r\n\r\n\r\nnames(H1N1)[names(H1N1) == 'CONCERN LEVEL'] <- \"CONCERN_LEVEL\" #Renaming of variable \"Concern Level\"\r\n\r\n\r\n\r\n\r\n\r\nH1N1[H1N1 == '#N/A'] <- NA # Changing all the value with \"#N/A\" to actual missing value.\r\n\r\n\r\n\r\n\r\n\r\ncolMeans(is.na(H1N1)) #Check for missing values again.\r\n\r\n\r\n       VACC_H1N1_F        VACC_SEAS_F       B_H1N1_ANTIV \r\n       0.000000000        0.003997732        0.203132974 \r\n      B_H1N1_AVOID       B_H1N1_FMASK       B_H1N1_HANDS \r\n       0.207201588        0.201360930        0.202098100 \r\n      B_H1N1_LARGE       B_H1N1_RCONT       B_H1N1_TOUCH \r\n       0.203189680        0.203274738        0.204678197 \r\n     CONCERN_LEVEL               HQ23               HQ24 \r\n       0.203473207        0.854834137        0.963198185 \r\n            HQ24_B           INT_H1N1           INT_NEXT \r\n       0.994740573        0.255146016        0.692755883 \r\n          INT_SEAS          KNOW_H1N1                Q23 \r\n       0.459625744        0.204479728        0.960518855 \r\n               Q24              Q24_B             DOCREC \r\n       0.977417068        0.996597675        0.044031755 \r\n   ILI_DIAG_H1N1_F    ILI_DIAG_SEAS_F              ILI_F \r\n       0.961993195        0.961993195        0.020484831 \r\n       ILI_OTHER_F        ILI_TREAT_F              PSL_1 \r\n       0.016869861        0.922497874        1.000000000 \r\n             PSL_2                 Q9             Q9_NUM \r\n       1.000000000        1.000000000        1.000000000 \r\n     CHRONIC_MED_F   CLOSE_UNDER6MO_F    HEALTH_WORKER_F \r\n       0.031216331        0.225333144        0.224766090 \r\n PATIENT_CONTACT_F             AGEGRP     EDUCATION_COMP \r\n       0.264346470        0.000000000        0.242968528 \r\n        HH_CHILD_R             HISP_I           INC_CAT1 \r\n       0.007074001        0.000000000        0.213198185 \r\n            INSURE            MARITAL          N_ADULT_R \r\n       1.000000000        0.243592288        0.007074001 \r\n        N_PEOPLE_R                Q95         Q95_INDSTR \r\n       0.003118798        0.994527927        0.594074284 \r\n         Q95_OCCPN         RACEETH4_I         RENT_OWN_R \r\n       0.594074284        0.000000000        0.983612135 \r\n             SEX_I              STATE REAS_NOH1N1_AHAD_F \r\n       0.000000000        0.000000000        0.401020697 \r\nREAS_NOH1N1_ALLG_F REAS_NOH1N1_CANT_F REAS_NOH1N1_COST_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_DKNW_F REAS_NOH1N1_DWRK_F REAS_NOH1N1_GOTO_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_NDOC_F REAS_NOH1N1_NEVR_F REAS_NOH1N1_NNDD_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_NOTA_F REAS_NOH1N1_OTHR_F REAS_NOH1N1_REFD_F \r\n       0.401020697        0.401020697        0.401020697 \r\nREAS_NOH1N1_SAVE_F REAS_NOH1N1_SEFF_F REAS_NOH1N1_TIME_F \r\n       0.401020697        0.401020697        0.401020697 \r\n\r\nData will more than 50% of missing values are removed. 27 variables are wrangled into a new data set h1n1data.\r\n\r\n\r\nh1n1data <-H1N1 %>%\r\n  select(VACC_H1N1_F,\r\n                   VACC_SEAS_F,\r\n                   B_H1N1_ANTIV,\r\n                   B_H1N1_AVOID,\r\n                   B_H1N1_FMASK,\r\n                   B_H1N1_HANDS,\r\n                   B_H1N1_LARGE,\r\n                   B_H1N1_RCONT,\r\n                   B_H1N1_TOUCH,\r\n                   CONCERN_LEVEL,\r\n                   INT_H1N1,\r\n                   KNOW_H1N1,\r\n                   INT_SEAS,  \r\n                   DOCREC,\r\n                   CHRONIC_MED_F,\r\n                   CLOSE_UNDER6MO_F,         \r\n                   HEALTH_WORKER_F,\r\n                   PATIENT_CONTACT_F,\r\n                   AGEGRP,\r\n                   EDUCATION_COMP,\r\n                   HH_CHILD_R,\r\n                   INC_CAT1,\r\n                   MARITAL,\r\n                   RACEETH4_I,\r\n                   N_ADULT_R,\r\n                   SEX_I,\r\n                   STATE)\r\n\r\n\r\n\r\nThe column variables are transformed in factor(categorical) variables.\r\n\r\n\r\nh1n1data <- transform(h1n1data,\r\n                   VACC_H1N1_F= as.factor(VACC_H1N1_F),\r\n                   VACC_SEAS_F= as.factor(VACC_SEAS_F),\r\n                   B_H1N1_ANTIV= as.factor(B_H1N1_ANTIV),\r\n                   B_H1N1_AVOID= as.factor(B_H1N1_AVOID),\r\n                   B_H1N1_FMASK= as.factor(B_H1N1_FMASK),\r\n                   B_H1N1_HANDS= as.factor(B_H1N1_HANDS),\r\n                   B_H1N1_LARGE= as.factor(B_H1N1_LARGE),\r\n                   B_H1N1_RCONT= as.factor(B_H1N1_RCONT),\r\n                   B_H1N1_TOUCH= as.factor(B_H1N1_TOUCH),\r\n                   CONCERN_LEVEL= as.factor(CONCERN_LEVEL),\r\n                   INT_H1N1= as.factor(INT_H1N1),\r\n                   KNOW_H1N1= as.factor(KNOW_H1N1),\r\n                   DOCREC= as.factor(DOCREC),\r\n                   CHRONIC_MED_F= as.factor(CHRONIC_MED_F),\r\n                   CLOSE_UNDER6MO_F= as.factor(CLOSE_UNDER6MO_F),\r\n                   HEALTH_WORKER_F= as.factor(HEALTH_WORKER_F),\r\n                   AGEGRP= as.factor(AGEGRP),\r\n                   EDUCATION_COMP= as.factor(EDUCATION_COMP),\r\n                   HH_CHILD_R= as.factor(HH_CHILD_R),\r\n                   INC_CAT1= as.factor(INC_CAT1),\r\n                   MARITAL= as.factor(MARITAL),\r\n                   RACEETH4_I= as.factor(RACEETH4_I),\r\n                   N_ADULT_R= as.factor(N_ADULT_R),\r\n                   SEX_I= as.factor(SEX_I),\r\n                   STATE= as.factor(STATE),\r\n                   PATIENT_CONTACT_F = as.factor(PATIENT_CONTACT_F),\r\n                   INT_SEAS = as.factor(INT_SEAS)\r\n                   )\r\n\r\n\r\n\r\nThe code below added a column which recoded the various states into regions.\r\n\r\n\r\nregion <- read_csv(\"data/state_region.csv\")\r\n\r\n\r\n\r\n\r\n\r\nh1n1data$state_recoded <- str_to_title(h1n1data$STATE)\r\nh1n1data <- left_join(h1n1data, region,\r\n                      by=c(\"state_recoded\" = \"State\"))\r\n\r\n\r\n\r\n\r\n\r\nsummary(h1n1data)\r\n\r\n\r\n VACC_H1N1_F VACC_SEAS_F  B_H1N1_ANTIV B_H1N1_AVOID B_H1N1_FMASK\r\n No :53471   No  :38210   No  :53438   No  :15263   No  :52444  \r\n Yes:17069   Yes :32048   Yes : 2773   Yes :40661   Yes : 3892  \r\n             NA's:  282   NA's:14329   NA's:14616   NA's:14204  \r\n                                                                \r\n                                                                \r\n                                                                \r\n                                                                \r\n B_H1N1_HANDS B_H1N1_LARGE B_H1N1_RCONT B_H1N1_TOUCH CONCERN_LEVEL\r\n No  : 9813   No  :36252   No  :37220   No  :17939   0   : 6861   \r\n Yes :46471   Yes :19955   Yes :18981   Yes :38163   1   :17218   \r\n NA's:14256   NA's:14333   NA's:14339   NA's:14438   2   :22490   \r\n                                                     3   : 9618   \r\n                                                     NA's:14353   \r\n                                                                  \r\n                                                                  \r\n INT_H1N1     KNOW_H1N1    INT_SEAS      DOCREC      CHRONIC_MED_F\r\n 0   :17731   0   :30895   0   :15490   0   : 1948   No  :51265   \r\n 1   :19663   1   : 5251   1   :13543   1   :40462   Yes :17073   \r\n 2   : 9961   2   :19970   2   : 5670   2   : 8687   NA's: 2202   \r\n 3   : 5187   NA's:14424   3   : 3415   3   : 2534                \r\n NA's:17998                NA's:32422   4   :13803                \r\n                                        NA's: 3106                \r\n                                                                  \r\n CLOSE_UNDER6MO_F HEALTH_WORKER_F PATIENT_CONTACT_F\r\n No  :50032       No  :48599      No  :46951       \r\n Yes : 4613       Yes : 6086      Yes : 4942       \r\n NA's:15895       NA's:15855      NA's:18647       \r\n                                                   \r\n                                                   \r\n                                                   \r\n                                                   \r\n                AGEGRP               EDUCATION_COMP  HH_CHILD_R  \r\n 10 - 17 Years     : 6833   < 12 Years      : 4995   0   :39356  \r\n 18 - 34 Years     :11037   12 Years        :12158   1   :12383  \r\n 35 - 44 Years     : 8243   College Graduate:21376   2   :11333  \r\n 45 - 54 Years     :11071   Some College    :14872   3   : 6969  \r\n 55 - 64 Years     :11685   NA's            :17139   NA's:  499  \r\n 6 Months - 9 Years: 7332                                        \r\n 65+ Years         :14339                                        \r\n               INC_CAT1            MARITAL     \r\n $75,001 - $100,000:19781   Married    :28539  \r\n $50,001 - $75,000 : 9985   Not Married:24818  \r\n $35,001 - $50,000 : 7976   NA's       :17183  \r\n $15,001 - $25,000 : 5805                      \r\n $25,001 - $35,000 : 5134                      \r\n (Other)           : 6820                      \r\n NA's              :15039                      \r\n                                 RACEETH4_I    N_ADULT_R   \r\n Hispanic                             : 5469   1   :18654  \r\n Non-Hispanic, Black Only             : 5776   2   :40293  \r\n Non-Hispanic, Other or Multiple Races: 4626   3   : 7996  \r\n Non-Hispanic, White Only             :54669   4   : 3098  \r\n                                               NA's:  499  \r\n                                                           \r\n                                                           \r\n    SEX_I                        STATE       state_recoded     \r\n Female:40314   TEXAS               : 1720   Length:70540      \r\n Male  :30226   NEW MEXICO          : 1678   Class :character  \r\n                CALIFORNIA          : 1637   Mode  :character  \r\n                GEORGIA             : 1605                     \r\n                MARYLAND            : 1584                     \r\n                DISTRICT OF COLUMBIA: 1581                     \r\n                (Other)             :60735                     \r\n    Region         \r\n Length:70540      \r\n Class :character  \r\n Mode  :character  \r\n                   \r\n                   \r\n                   \r\n                   \r\n\r\nThe predictors are plotted against the target variable to check for complete or quasi-complete separation.\r\n\r\n\r\n\r\n\r\n\r\nPlots I\r\n\r\n\r\n\r\n\r\n\r\nPlots II\r\n\r\n\r\n\r\n\r\nPlots III\r\n\r\n\r\n\r\n\r\n\r\nThe new dataframe h1n1model is created. 3 variables with complete/quasi-complete separation were removed.\r\n\r\n\r\nh1n1model <- h1n1data #new dataframe for predictive modeling\r\n              \r\n\r\nh1n1model <-select(h1n1model,-c(INT_H1N1,B_H1N1_ANTIV,INT_SEAS, state_recoded, Region)) #Remove variable with complete separation from dataset.\r\n\r\n\r\nh1n1model <- h1n1model %>% #Omitting na in order as some models unable to process with missing values. \r\n             na.omit\r\n\r\nsummary(h1n1model) #To check the data again.\r\n\r\n\r\n VACC_H1N1_F VACC_SEAS_F B_H1N1_AVOID B_H1N1_FMASK B_H1N1_HANDS\r\n No :30432   No :20780   No :10338    No :36863    No : 6618   \r\n Yes: 9075   Yes:18727   Yes:29169    Yes: 2644    Yes:32889   \r\n                                                               \r\n                                                               \r\n                                                               \r\n                                                               \r\n                                                               \r\n B_H1N1_LARGE B_H1N1_RCONT B_H1N1_TOUCH CONCERN_LEVEL KNOW_H1N1\r\n No :25744    No :26430    No :12467    0: 4486       0:21859  \r\n Yes:13763    Yes:13077    Yes:27040    1:12541       1: 2903  \r\n                                        2:16183       2:14745  \r\n                                        3: 6297                \r\n                                                               \r\n                                                               \r\n                                                               \r\n DOCREC    CHRONIC_MED_F CLOSE_UNDER6MO_F HEALTH_WORKER_F\r\n 0:  917   No :28467     No :36077        No :34785      \r\n 1:24438   Yes:11040     Yes: 3430        Yes: 4722      \r\n 2: 5363                                                 \r\n 3: 1271                                                 \r\n 4: 7518                                                 \r\n                                                         \r\n                                                         \r\n PATIENT_CONTACT_F                AGEGRP              EDUCATION_COMP \r\n No :35658         10 - 17 Years     :   0   < 12 Years      : 3300  \r\n Yes: 3849         18 - 34 Years     :8122   12 Years        : 8593  \r\n                   35 - 44 Years     :6220   College Graduate:16515  \r\n                   45 - 54 Years     :8283   Some College    :11099  \r\n                   55 - 64 Years     :8367                           \r\n                   6 Months - 9 Years:   0                           \r\n                   65+ Years         :8515                           \r\n HH_CHILD_R               INC_CAT1            MARITAL     \r\n 0:27196    $10,001 - $15,000 : 1979   Married    :21477  \r\n 1: 4939    $15,001 - $25,000 : 4335   Not Married:18030  \r\n 2: 4570    $25,001 - $35,000 : 3826                      \r\n 3: 2802    $35,001 - $50,000 : 5879                      \r\n            $50,001 - $75,000 : 7082                      \r\n            $75,001 - $100,000:13303                      \r\n            <= $10,000        : 3103                      \r\n                                 RACEETH4_I    N_ADULT_R\r\n Hispanic                             : 2581   1:11389  \r\n Non-Hispanic, Black Only             : 3083   2:22005  \r\n Non-Hispanic, Other or Multiple Races: 2274   3: 4399  \r\n Non-Hispanic, White Only             :31569   4: 1714  \r\n                                                        \r\n                                                        \r\n                                                        \r\n    SEX_I                        STATE      \r\n Female:23154   NEW MEXICO          :  964  \r\n Male  :16353   DISTRICT OF COLUMBIA:  926  \r\n                TEXAS               :  926  \r\n                CALIFORNIA          :  896  \r\n                ARIZONA             :  878  \r\n                VIRGINIA            :  863  \r\n                (Other)             :34054  \r\n\r\n3 Modeling\r\n3.1 Literature Review: Choosing the right Modeling Package\r\nThe R caret package is a set of functions that streamlines the process for predictive model building. It’s current release consist 238 models.As different modeling functions has different syntax for modeling training and prediction, it will be difficult to keep track of which algorithms are in which package. For example, a random forest model will be using randomforest() syntax to run the model and a neural network model requires the neuralnet() syntax. Moreover, each of the algorithm will have their own arguments, making it difficult and time-consuming if different models are required to be used in the same code.\r\nThere is no need to call for the library for the different modeling packages using caret. caret will assist to load the required packages when used and if the package is missing, there will be a prompt for installation.\r\nThe train() function in caret has multiple functions:\r\nBuilding a model using a specific algorithm\r\nCross validating the model\r\nTune the parameters for optimal model performance\r\nChoose the optimal model based on a given evaluation metric\r\nPreprocessing\r\nThe caret package made it easier by combining the data pre-processing, model hyperparameter tuning within the same package. It allows quick change of model with minor syntax change, allowing it the most suitable model to be found.\r\n3.2 Data Splitting\r\nAs the H1N1 vaccination (VACC_H1N1_F) is the target variable is important for analysis, a balance of the target variable across the training/test sets, the function createDataPartition was used to create training/testing sets using stratified random sampling.\r\nData is split with 80% as training data and 20% are testing data.In place of partitioning a validation dataset, the traincontrol function is used for the cross-validation of the training data set.\r\nThe below code shows the spliting of the dataset.\r\n\r\n\r\nset.seed(123)\r\n\r\n# define an 80%/20% train/test split of the h1n1model data set\r\nsplit=0.80 \r\ntrainIndex <- createDataPartition(h1n1model$VACC_H1N1_F, p=split, list=FALSE)\r\ndata_train <- h1n1model[ trainIndex,]\r\ndata_test <- h1n1model[-trainIndex,]\r\n\r\n\r\n\r\n3.3 Model Tuning\r\nThe function trainControl generates parameters that further control how models are created, with different resampling methods like bootstrap re-sampling, k-fold cross validation. In the code below, the k-fold cross validation method with number = referring to the number of folds being used. The repeated k-fold cross validation method involves splitting the dataset into k-subsets and repeating in a number of time. For each subset is held out while the model is trained on all other subsets. This process is completed until accuracy is determine for each instance in the dataset, and an overall accuracy estimate is provided.\r\n\r\n\r\nfitControl <- trainControl(\r\n  method = \"cv\",\r\n  number = 5,\r\n  classProbs = TRUE,\r\n  summaryFunction = twoClassSummary, #twoClassSummary computes the sensitivity, specificity and aread under the ROC curve. \r\n  savePredictions = TRUE)\r\n\r\n\r\n\r\nThere are two main ways of tuning the model within the caret package, using tuneLength or tuneGrid.\r\nThe tuneLength parameter allows the user to enter a value which will determine the number of default values being used as the main parameter for a specific model. The number used can be applicable throughout all the models. The tuneGrid function create a dataframe to store the tuning parameter grid specified by the user. It allows the user to determine which are the values a model will take as it’s main parameter. The parameters in the tuneGrid is model specific. Using tuneGrid will be more applicable as it provides the user more model customizability and fine tuning.\r\nFor random forest using the ranger method in caret, three options are available for tuning the model. Firstly, mtry which refers to the number of variables randomly sampled as candidates at each split. Split rule defines which splitting method is used. The default used is Gini where the split minimizes the the Gini impurtity for classification. The minimum node size refers to the minimum number of observations in a terminal node.\r\nAccording the research (Probst et al.,2019), mtry has the most influence over the model performance and the best value of mtry depends on the number of variables that are related to the outcome.\r\n\r\n\r\n# Random Forest:\r\nset.seed(123)\r\n\r\nm=4\r\nns=10\r\n\r\nrf_grid <- expand.grid(\r\n                mtry = 2:m,\r\n                splitrule =\"gini\",\r\n                min.node.size = 10\r\n                      )\r\n\r\nmodel_rf <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"ranger\",\r\n                  metric = \"ROC\",\r\n                  importance = \"impurity\",\r\n                  tuneGrid = rf_grid)\r\n\r\nmodel_rf\r\n\r\n\r\nRandom Forest \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results across tuning parameters:\r\n\r\n  mtry  ROC        Sens       Spec     \r\n  2     0.8335559  0.9952764  0.0738292\r\n  3     0.8390148  0.9692352  0.2856749\r\n  4     0.8417187  0.9558860  0.3809917\r\n\r\nTuning parameter 'splitrule' was held constant at a value of\r\n gini\r\nTuning parameter 'min.node.size' was held constant at a\r\n value of 10\r\nROC was used to select the optimal model using the largest value.\r\nThe final values used for the model were mtry = 4, splitrule =\r\n gini and min.node.size = 10.\r\n\r\nThe rpart2 method within the caret package allows for the tuning for the maximum depth of the tree. This tuning variable can help to limit the decsion tree model from growing too deep which might cause over-fitting.\r\n\r\n\r\n#Decision Tree\r\nset.seed(123)\r\n\r\ndepth = 5 #User-defined maximum depth of decision tree\r\n\r\ndt_grid<- expand.grid(maxdepth = depth)\r\n\r\nmodel_dt <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"rpart2\",\r\n                  metric = \"ROC\",\r\n                  tuneGrid = dt_grid\r\n                  )\r\n\r\nmodel_dt\r\n\r\n\r\nCART \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results:\r\n\r\n  ROC        Sens       Spec     \r\n  0.7841742  0.9484104  0.4137741\r\n\r\nTuning parameter 'maxdepth' was held constant at a value of 5\r\n\r\nThe principle behind K-Nearest Neighbor(KNN) algorithm is to find K predefined number of training samples that are closest in the distance to a new point & predict a label for our new point using these samples. For classification the KNN method starts by identifying the k most similar training observations (i.e. neighbors) to the new observation, and then assigns the observation to the class containing the majority of its neighbors.\r\nThe choice of k considerably impacts the output of KNN model. k = 1 corresponds to a highly flexible method resulting to a training error rate of 0 (over-fitting), but the test error rate may be quite high. The value of optimal k is usually the square root of N, where N is the total number of samples.\r\n\r\n\r\n#K-Nearest Neighbors\r\nset.seed(123)\r\n\r\nkv=10  #User-defined k value\r\n\r\nknn_grid <- expand.grid(k= kv)\r\n\r\nmodel_knn <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"knn\",\r\n                  metric = \"ROC\",\r\n                  tuneGrid = knn_grid\r\n                  )\r\n\r\nmodel_knn\r\n\r\n\r\nk-Nearest Neighbors \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results:\r\n\r\n  ROC        Sens       Spec     \r\n  0.8048322  0.9500945  0.3513774\r\n\r\nTuning parameter 'k' was held constant at a value of 10\r\n\r\nFor the neural network(nnet) model,there are two tuning parameters, which need to be set. First is the number of nodes in the hidden layer and second, it is the value of the “weight decay” parameter.\r\nThe hidden layer of the neural network is the intermediate layer between the input and output layer of a neuron network (Panchal & Panchal, 2014, p. 460). The hidden nodes might cause overfitting when too many neurons(hidden nodes) are present in the network. The purpose of the weight decay factor is to prevent overfitting.\r\n\r\n\r\n#Neural Network  \r\nset.seed(123)\r\n\r\nsz = 1 #User-defined number of hidden nodes\r\ndc = 0 #USer-defined decay rate\r\n\r\nnnet_grid <- expand.grid( size = sz,\r\n                          decay = dc)\r\n\r\n\r\nmodel_nnet <- train(VACC_H1N1_F~., \r\n                  data=data_train, \r\n                  trControl = fitControl, \r\n                  method = \"nnet\",\r\n                  metric = \"ROC\",\r\n                  tuneGrid = nnet_grid\r\n                  )\r\n\r\n\r\n# weights:  99\r\ninitial  value 26589.627274 \r\niter  10 value 13626.461983\r\niter  20 value 13376.340522\r\niter  30 value 12915.052594\r\niter  40 value 12606.753114\r\niter  50 value 12331.349382\r\niter  60 value 11946.723445\r\niter  70 value 11776.270369\r\niter  80 value 11732.724596\r\niter  90 value 11718.627201\r\niter 100 value 11717.572046\r\nfinal  value 11717.572046 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 17171.750195 \r\niter  10 value 11380.634022\r\niter  20 value 11309.563841\r\niter  30 value 11278.590198\r\niter  40 value 11264.527582\r\niter  50 value 11259.782750\r\niter  60 value 11256.844758\r\niter  70 value 11253.710980\r\niter  80 value 11241.607724\r\niter  90 value 11232.658714\r\niter 100 value 11232.389316\r\nfinal  value 11232.389316 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 19684.645375 \r\niter  10 value 10712.335323\r\niter  20 value 10503.529519\r\niter  30 value 10471.490428\r\niter  40 value 10447.308989\r\niter  50 value 10426.685950\r\niter  60 value 10414.830002\r\niter  70 value 10410.289543\r\niter  80 value 10409.708839\r\nfinal  value 10409.698890 \r\nconverged\r\n# weights:  99\r\ninitial  value 17241.041006 \r\niter  10 value 13626.329956\r\niter  20 value 12536.157114\r\niter  30 value 11488.105019\r\niter  40 value 11293.383176\r\niter  50 value 11148.360692\r\niter  60 value 11045.260594\r\niter  70 value 10976.829467\r\niter  80 value 10943.918263\r\niter  90 value 10928.649520\r\niter 100 value 10914.121349\r\nfinal  value 10914.121349 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 16605.060349 \r\niter  10 value 12063.508758\r\niter  20 value 11550.729798\r\niter  30 value 11528.194364\r\niter  40 value 11510.989549\r\niter  50 value 11503.611516\r\niter  60 value 11493.210692\r\niter  70 value 11487.004214\r\niter  80 value 11481.522394\r\niter  90 value 11473.852666\r\niter 100 value 11468.934232\r\nfinal  value 11468.934232 \r\nstopped after 100 iterations\r\n# weights:  99\r\ninitial  value 18646.728694 \r\niter  10 value 14221.978222\r\niter  20 value 14022.646547\r\niter  30 value 13911.598167\r\niter  40 value 13319.594765\r\niter  50 value 12953.457998\r\niter  60 value 12841.826303\r\niter  70 value 12639.090264\r\niter  80 value 12554.912863\r\niter  90 value 12535.639135\r\niter 100 value 12531.439084\r\nfinal  value 12531.439084 \r\nstopped after 100 iterations\r\n\r\nmodel_nnet\r\n\r\n\r\nNeural Network \r\n\r\n31606 samples\r\n   23 predictor\r\n    2 classes: 'No', 'Yes' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (5 fold) \r\nSummary of sample sizes: 25285, 25285, 25284, 25285, 25285 \r\nResampling results:\r\n\r\n  ROC        Sens       Spec     \r\n  0.7411793  0.9238097  0.3256198\r\n\r\nTuning parameter 'size' was held constant at a value of 1\r\n\r\nTuning parameter 'decay' was held constant at a value of 0\r\n\r\n4. Plotting Variable Importance\r\nVariable importance helps to identify most important variables that contribute most significantly to the target variable.Being able to select the most important predictor variables that explains the major part of variance of a target variable can help to identify and build high performing models.\r\nThe variable importance of each trained model is plotted.(Note:kNN does not have variable importance)\r\n\r\n\r\nVariable Importance of Random Forest\r\n\r\n\r\nrfImp <- varImp(model_rf)\r\ndtImp <- varImp(model_dt)\r\nnnetImp <- varImp(model_nnet)\r\n\r\nNo_Var=5 #No.of variable importance to be shown can be user-defined.\r\n\r\ng1 <- rfImp$importance %>% \r\n  as.data.frame() %>%\r\n  rownames_to_column() %>%\r\n  arrange(Overall) %>%\r\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\r\n  top_n(No_Var,Overall) %>%  #top 5 Importance\r\n  ggplot(aes(x = rowname, y = Overall))+\r\n    geom_col(color=\"black\",fill = \"light blue\")+\r\n    coord_flip()+\r\n    xlab(\"Variable\")+\r\n    ggtitle(\"Variable Importance of Random Forest Model\") + \r\n    theme_minimal() +\r\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\r\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\r\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\r\n\r\nggplotly(g1, tooltip = c(\"rowname\", \"Overall\"))\r\n\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[18.2359585268045,24.8869169214332,30.709481313405,69.2805079158989,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: HEALTH_WORKER_FYes<br />Overall:  18.23596\",\"rowname: DOCREC2<br />Overall:  24.88692\",\"rowname: DOCREC1<br />Overall:  30.70948\",\"rowname: DOCREC4<br />Overall:  69.28051\",\"rowname: VACC_SEAS_FYes<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":130.776255707763},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Random Forest Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"HEALTH_WORKER_FYes\",\"DOCREC2\",\"DOCREC1\",\"DOCREC4\",\"VACC_SEAS_FYes\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"HEALTH_WORKER_FYes\",\"DOCREC2\",\"DOCREC1\",\"DOCREC4\",\"VACC_SEAS_FYes\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"1ed447e33a7f\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"1ed447e33a7f\",\"visdat\":{\"1ed447e33a7f\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nVariable Importance of Decision Tree\r\n\r\n\r\ng2 <- dtImp$importance %>% \r\n  as.data.frame() %>%\r\n  rownames_to_column() %>%\r\n  arrange(Overall) %>%\r\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\r\n  top_n(No_Var,Overall) %>%  #top 5 Importance\r\n  ggplot(aes(x = rowname, y = Overall))+\r\n    geom_col(color=\"black\",fill = \"light blue\")+\r\n    coord_flip()+\r\n    xlab(\"Variable\")+\r\n    ggtitle(\"Variable Importance of Decision Tree Model\") + \r\n    theme_minimal() +\r\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\r\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\r\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\r\n\r\nggplotly(g2, tooltip = c(\"rowname\", \"Overall\"))\r\n\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[24.9272016160619,25.258635091715,27.4749244977431,65.8105301166099,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: HEALTH_WORKER_FYes<br />Overall:  24.92720\",\"rowname: DOCREC1<br />Overall:  25.25864\",\"rowname: DOCREC2<br />Overall:  27.47492\",\"rowname: VACC_SEAS_FYes<br />Overall:  65.81053\",\"rowname: DOCREC4<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":130.776255707763},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Decision Tree Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"HEALTH_WORKER_FYes\",\"DOCREC1\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC4\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"HEALTH_WORKER_FYes\",\"DOCREC1\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC4\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"1ed4388cf52\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"1ed4388cf52\",\"visdat\":{\"1ed4388cf52\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nVariable Importance of Neural Network\r\n\r\n\r\ng3 <- nnetImp$importance %>% \r\n  as.data.frame() %>%\r\n  rownames_to_column() %>%\r\n  arrange(Overall) %>%\r\n  mutate(rowname = forcats::fct_inorder(rowname )) %>%\r\n  top_n(No_Var,Overall) %>%  #top 5 Importance\r\n  ggplot(aes(x = rowname, y = Overall))+\r\n    geom_col(color=\"black\",fill = \"light blue\")+\r\n    coord_flip()+\r\n    xlab(\"Variable\")+\r\n    ggtitle(\"Variable Importance of Neural Network Model\") + \r\n    theme_minimal() +\r\n    theme(panel.background = element_rect(fill = \"gray80\", color = \"gray80\", size =0.5, linetype = \"solid\"),\r\n       panel.grid.major = element_line(size =0.5, linetype = \"solid\", color = \"white\"), #major refers to grid line at values\r\n       panel.grid.minor = element_line(size =0.25, linetype = \"solid\", color = \"white\")) # minor refers line in between grid values\r\n\r\nggplotly(g3, tooltip = c(\"rowname\", \"Overall\"))\r\n\r\n\r\n\r\n{\"x\":{\"data\":[{\"orientation\":\"h\",\"width\":[0.9,0.9,0.9,0.9,0.9],\"base\":[0,0,0,0,0],\"x\":[31.8277313713564,32.7172301979378,50.6010822123337,99.5454136385648,100],\"y\":[1,2,3,4,5],\"text\":[\"rowname: DOCREC4<br />Overall:  31.82773\",\"rowname: PATIENT_CONTACT_FYes<br />Overall:  32.71723\",\"rowname: DOCREC2<br />Overall:  50.60108\",\"rowname: VACC_SEAS_FYes<br />Overall:  99.54541\",\"rowname: DOCREC3<br />Overall: 100.00000\"],\"type\":\"bar\",\"marker\":{\"autocolorscale\":false,\"color\":\"rgba(173,216,230,1)\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,1)\"}},\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":45.4063926940639,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":142.465753424658},\"plot_bgcolor\":\"rgba(204,204,204,1)\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"title\":{\"text\":\"Variable Importance of Neural Network Model\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":17.5342465753425},\"x\":0,\"xref\":\"paper\"},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[-5,105],\"tickmode\":\"array\",\"ticktext\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"tickvals\":[0,25,50,75,100],\"categoryorder\":\"array\",\"categoryarray\":[\"0\",\"25\",\"50\",\"75\",\"100\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"Overall\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[0.4,5.6],\"tickmode\":\"array\",\"ticktext\":[\"DOCREC4\",\"PATIENT_CONTACT_FYes\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC3\"],\"tickvals\":[1,2,3,4,5],\"categoryorder\":\"array\",\"categoryarray\":[\"DOCREC4\",\"PATIENT_CONTACT_FYes\",\"DOCREC2\",\"VACC_SEAS_FYes\",\"DOCREC3\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(255,255,255,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Variable\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":false,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895}},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"1ed4654d142d\":{\"x\":{},\"y\":{},\"type\":\"bar\"}},\"cur_data\":\"1ed4654d142d\",\"visdat\":{\"1ed4654d142d\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n5. Model Comparision by ROC/AUC and Visualisations\r\nNote: Compare the model, note the predicted results.\r\nThe ROC (Receiver Operating Characteristic) curve is used to evaluate the strength of a classification model and also to compare between classification models.The ROC curve shows the trade-off between the true positive rate and the false positive rate. To compare between models, the AUC (area under the curve) is used. AUC provides an aggregate measure of performance of a model across the classification thresholds. It is a representation of the model’s capability to distinguish between the classes.\r\n5.1 Comparing ROC Packages\r\nThe following R packages ROCR, pROC and plotROC are used to plot the ROC curves of the predictive models. The packages are later compared on usability, comprehensiveness and visualization of ROC curves.\r\n5.1.1 Using ROCR Package\r\n\r\n\r\n#using ROCR package \r\n\r\n#ROC Curve for Random Forest\r\nrf_pred <- prediction(model_rf$pred$Yes,model_rf$pred$obs)\r\nrf_perf <- performance(rf_pred,\"tpr\",\"fpr\")\r\nplot(rf_perf, main = \"ROC Curves of Models\")\r\n\r\n\r\n#ROC Curve for Decision Tree\r\ndt_pred <-prediction(model_dt$pred$Yes,model_dt$pred$obs)\r\ndt_perf <- performance(dt_pred,\"tpr\",\"fpr\")\r\nplot(dt_perf, add = TRUE, col = \"blue\")\r\n\r\n#ROC Curve for KNN\r\nknn_pred <-prediction(model_knn$pred$Yes,model_knn$pred$obs)\r\nknn_perf <- performance(knn_pred,\"tpr\",\"fpr\")\r\nplot(knn_perf, add = TRUE, col = \"red\")\r\n\r\n#ROC Curve for Neural Network\r\nnnet_pred <-prediction(model_nnet$pred$Yes,model_nnet$pred$obs)\r\nnnet_perf <- performance(nnet_pred,\"tpr\",\"fpr\")\r\nplot(nnet_perf, add = TRUE, col = \"green\")\r\n\r\nlegend(\"right\", legend = c(\"Random Forest\",\"Decision Tree\",\"KNN\",\"Neural Network\"),bty= 'n',cex = 1, lty =1, \r\n       col= c(\"black\",\"blue\",\"red\",\"green\"))\r\n\r\n\r\n\r\n\r\n5.1.2 Using pROC Package\r\n\r\n\r\n#using pROC package\r\n\r\n#ROC Curve for Random Forest\r\nrf_pROC <- roc(model_rf$pred$obs,model_rf$pred$Yes )\r\nplot(rf_pROC, print.auc = TRUE, grid = TRUE, col = \"red\")\r\n\r\n#ROC Curve for Decision Tree\r\ndt_pROC <- roc(model_dt$pred$obs,model_dt$pred$Yes )\r\nplot(dt_pROC, print.auc = TRUE, col = \"blue\", add = TRUE, print.auc.y = .4)\r\n\r\n#ROC Curve for KNN\r\nknn_pROC <- roc(model_knn$pred$obs,model_knn$pred$Yes )\r\nplot(knn_pROC, print.auc = TRUE, col = \"green\", add = TRUE, print.auc.y = .3)\r\n\r\n#ROC Curve for Neural Network\r\nnnet_pROC <- roc(model_nnet$pred$obs,model_nnet$pred$Yes )\r\nplot(nnet_pROC, print.auc = TRUE, col = \"black\", add = TRUE, print.auc.y = .2)\r\n\r\n\r\n\r\n\r\n5.1.3 Using plotROC Package\r\n\r\n\r\n#USing plotROC package\r\n              ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes, color=\"Random Forest\"), model_rf$pred,n.cuts = 0) + #ROC Curve for Random Forest\r\n              geom_roc(aes(d = obs, m = Yes, color=\"Decision Tree\"), model_dt$pred,n.cuts = 0) + #ROC Curve for Decision Tree\r\n              geom_roc(aes(d = obs, m = Yes, color=\"KNN\"), model_knn$pred,n.cuts = 0) + #ROC Curve for KNN \r\n              geom_roc(aes(d = obs, m = Yes, color=\"Neural Network\"), model_nnet$pred,n.cuts = 0) +  #ROC Curve for Neural Network\r\n              scale_color_manual(values=c(\"Random Forest\"=\"red\", \"Decision Tree\"=\"blue\",\"KNN\"=\"green\",\"Neural Network\"=\"black\"), \r\n              name=\"Models\", guide=\"legend\") + \r\n              coord_equal()+\r\n              style_roc(theme = theme_grey,xlab = \"1-Specificity\", ylab =\"Sensitivity\")+\r\n              theme(legend.position = \"bottom\")+\r\n              labs(title=\"ROC Plots Comparison\")\r\n\r\n\r\n\r\n\r\n5.1.4 ROC Package Comparison\r\nBased on report (Robin et al., 2011, p. 12), the pROC is a report dedicated to ROC analysis compared to ROCR. Both pROC and ROCR use simple commands to for plotting the ROC curve. ROCR requiring only 3 commands and pROC* requiring 2 commands for a basic plot. One key difference between the plotROC package and the other two, plotROC allows the use of ggplot’s geoms to plot the ROC curve, enabling usage of the extensive ggplot package. where the other two packages use the base plot function in R.\r\nThus, for the purpose of a ROC visualisation for shiny,plotROC is deemed to be the more appropriate package for it’s usability for plotting via ggplot.\r\n5.2 Obtaining the AUC Table\r\n\r\n\r\nCombineAUC <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes,), model_rf$pred))\r\n\r\nAUCdt <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes), model_dt$pred)) \r\n\r\nAUCknn <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes), model_knn$pred)) \r\n\r\nAUCnnet <- calc_auc(ggplot() + \r\n              geom_roc(aes(d = obs, m = Yes), model_nnet$pred)) \r\n           \r\n\r\nCombineAUC <- bind_rows(CombineAUC,AUCdt,AUCknn,AUCnnet) #Combining AUC values of each model into one dataframe\r\n\r\nModel <-c(\"Random Forest\", \"Decision Tree\",\"kNN\",\"Neural Network\")\r\nAUC <- CombineAUC$AUC\r\nFinalAUC <- data.frame(Model,AUC)\r\n\r\nggplot(FinalAUC, aes( x=Model, y= AUC))+\r\n                  geom_bar(stat = \"Identity\", fill= \"#E7B800\", color =\"black\")+\r\n                  geom_text(aes(y=AUC, ymax= AUC, label = round(AUC, 3)))+\r\n                  coord_flip()+\r\n                  geom_hline(yintercept = AUC[AUC == max(AUC)],color = \"red\",linetype =2)+\r\n                  theme_grey()\r\n\r\n\r\n\r\n\r\nAs seen from both the AUC table and the ROC curve, it is shown the Random Forest model has performed the best with the highest AUC at 0.837 and highest ROC curve.\r\n5.3 Comparing Model Performance via Resampling\r\nThe caret’s resamples() function assist to resampling performance on the final model produced during the model training.It creates summary statistics (mean, min, max, etc.) for each performance metric for the list of models.\r\n\r\n\r\nrvalues <-resamples(list('Random Forest'=model_rf,'Decision Tree'=model_dt,kNN=model_knn, 'Neural Network'=model_nnet))\r\nsummary(rvalues)\r\n\r\n\r\n\r\nCall:\r\nsummary.resamples(object = rvalues)\r\n\r\nModels: Random Forest, Decision Tree, kNN, Neural Network \r\nNumber of resamples: 5 \r\n\r\nROC \r\n                    Min.   1st Qu.    Median      Mean   3rd Qu.\r\nRandom Forest  0.8325592 0.8366193 0.8424705 0.8417187 0.8480867\r\nDecision Tree  0.7774597 0.7819551 0.7825665 0.7841742 0.7869916\r\nkNN            0.7918626 0.7983920 0.8044332 0.8048322 0.8136617\r\nNeural Network 0.6875573 0.7225108 0.7347946 0.7411793 0.7355749\r\n                    Max. NA's\r\nRandom Forest  0.8488579    0\r\nDecision Tree  0.7918983    0\r\nkNN            0.8158115    0\r\nNeural Network 0.8254590    0\r\n\r\nSens \r\n                    Min.   1st Qu.    Median      Mean   3rd Qu.\r\nRandom Forest  0.9515301 0.9533785 0.9548255 0.9558860 0.9574861\r\nDecision Tree  0.9439310 0.9463956 0.9486548 0.9484104 0.9492813\r\nkNN            0.9474225 0.9480386 0.9498870 0.9500945 0.9501027\r\nNeural Network 0.8264531 0.8540041 0.9385911 0.9238097 1.0000000\r\n                    Max. NA's\r\nRandom Forest  0.9622099    0\r\nDecision Tree  0.9537893    0\r\nkNN            0.9550216    0\r\nNeural Network 1.0000000    0\r\n\r\nSpec \r\n                    Min.   1st Qu.    Median      Mean   3rd Qu.\r\nRandom Forest  0.3719008 0.3739669 0.3760331 0.3809917 0.3856749\r\nDecision Tree  0.4001377 0.4008264 0.4166667 0.4137741 0.4228650\r\nkNN            0.3312672 0.3326446 0.3615702 0.3513774 0.3629477\r\nNeural Network 0.0000000 0.0000000 0.4366391 0.3256198 0.5488981\r\n                    Max. NA's\r\nRandom Forest  0.3973829    0\r\nDecision Tree  0.4283747    0\r\nkNN            0.3684573    0\r\nNeural Network 0.6425620    0\r\n\r\nA box-whiskers plot is used to visualized the re-sampling distributions of the models.The best performing model on resamples based on mean ROC score was Random Forest model.Neural network model has the highest sensitivity.\r\n\r\n\r\ntrellis.par.set()\r\nbwplot(rvalues,layout= c(3,1))\r\n\r\n\r\n\r\n\r\n6. Proposed Visualisation from Shiny Module\r\n\r\n7. Conclusion/Reflections\r\nThe purpose of this post was to review the packages available for predictive modeling, how to compare the results of those modes and how to incorporate into a Shiny App. As highlighted in section 3, the caret package was found to be a “wholesome” package when it comes to model building, providing most of the functions required to predictive modeling.\r\nUser of the shiny app would be able to tune and explore the four different models made available. Various visualizations to assess the models were provided for users to assess the parameters and models used.\r\nReferences\r\nProbst, P., Wright, M., & Boulesteix, A.-L. (2019). Hyperparameters and Tuning Strategies for Random Forest. https://arxiv.org/pdf/1804.03515.pdf\r\nBand, A. (2020b, May 23). How to find the optimal value of K in KNN? - Towards Data Science. Medium. https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb#:%7E:text=The%20optimal%20K%20value%20usually,be%20aware%20of%20the%20outliers. 3.Robin, X., Turck, N., Hainard, A., Tiberti, N., Lisacek, F., Sanchez, J. C., & Müller, M. (2011). pROC: an open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12(1), 12. https://doi.org/10.1186/1471-2105-12-77 4.Panchal, F. S., & Panchal, M. (2014). Review on Methods of Selecting Number of Hidden Nodes in Artificial Neural Network. International Journal of Computer Science and Mobile Computing, 3(11), 455–464. https://www.ijcsmc.com/docs/papers/November2014/V3I11201499a19.pdf\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-04-10-predictive-modelling/predictive-modelling_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2021-04-11T18:29:08+08:00",
    "input_file": "predictive-modelling.utf8.md"
  },
  {
    "path": "posts/2021-03-21-dataviz-makeover-3/",
    "title": "DataViz Makeover 3",
    "description": "ISSS608 Visual Analytics and Applications: DataViz Makeover",
    "author": [
      {
        "name": "Desmond Lim",
        "url": {}
      }
    ],
    "date": "2021-03-21",
    "categories": [],
    "contents": "\r\n1. Original Visualisation\r\n\r\n2. Critiques and Suggestions on Original Visualization\r\n2.1 Clarity\r\nCritique\r\nSuggestions\r\nThe visualization is unable to provide further clarity/breakdown on the type of sub-events that occur.\r\nTo include variable information in charts and tooltips.\r\nThe event location dots overlap each other when all the events are chosen. i.e. the Battles (blue) event will cover any others below. Thus unable to visualise the actual events happening in the area.\r\nTo consolidate events into state level events for better visualization and less cluster on map.\r\nUnable to know which state/area the event has happened in. Only the latitude and longitude are shown in tool tip.\r\nTo include necessary variable information in charts and tooltips.\r\n2.2 Aesthetics\r\nCritique\r\nSuggestions\r\nThe y-axis of the line chart which stated “Count of Sheet1” is not properly titled.\r\nTo provide appropriate title to the axis to explain the chart.\r\nThe color scheme used for the difference event type is not optimal. i.e. Riots and strategic developments color shade is very close.\r\nTo ensure color theme used is visible and able to be easily differentiated.\r\nThe event location dots are cluttered covering the country names. No way of seeing which dots are on which country other than via the country filter.\r\nTo consolidate events into state level events for better visualisation and less clustered on map.\r\n2.3 Interactivity\r\nCritique\r\nSuggestions\r\nCountry filtering is done through a typical map filter function on the dashboard.\r\nTo use dashboard actions to allow interactive filtering of countries.\r\nThere is no way of comparing event changes for a certain reference year through the event type chart.\r\nTo create reference year choosing function directly on the chart to allow comparison between multiple reference years.\r\n3. Proposed Visualisation\r\n3.1 Sketch\r\n\r\n3.2 Advantages of New Visualisation\r\nThe new visualisation will be able to provide a better general overview of the conflict event situation in South East Asia through the choropleth map. Detailed information on events that occurred in each state will also be shown. By clicking on the country name on the dashboard, the specific country will be chosen and charts will change according to the chosen country, allowing more insights to be obtained. The two charts will be able to provide information not available in the original visualisation.\r\nInteractivity wise, the percentage change of events over the time period can be shown with a reference year which can be chosen by clicking any data point for that year in the chart. Changing the reference year will at the same time change the year parameter of the map, switching it to the reference year. The top 5 sub events that occurred in each country can also be shown in the charts provide details on the fatalities that occurred in those events.\r\n4. Data Visualisation Steps\r\n4.1 Data Source\r\nThe data used was obtained from the Armed Conflict Location & Event Data Project (ACLED). The datafiles contain dates, actors, locations, fatalities, and types of all reported political violence and protest events across Southeast Asia.\r\n4.2 Data Preparation in Tableau\r\nThe data set “Southeast-Asia_2010-2020_Oct31” was dragged into Tableau and fields were checked for discrepancy.\r\nThe unrelated fields are selected and hidden. \r\nThe variable “Admin1” was renamed as “State” and changed its geographic role to “State/Province” as shown. \r\n4.3 Geographic Map\r\nA calculated field called “Number of Events” is created as shown. \r\nThe “Longitude” measure was dragged to column and “Latitude” measure to rows \r\nThe “Country” measure was dragged to Detail card and “Number of Events” was dragged to the Color card. \r\nTo create another map layer above the current choropleth map, the “State” measure is dragged onto the map as shown. \r\nThe “State” measure is dragged to the Detail card, and the “Number of Events” to the Size card. This is to consolidate the number of events happening at a state level. \r\nThe color, size and opacity of the circle is adjusted.\r\nFor the “Country” layer, “State” measure was dragged into tooltip and changed to count distinct. \r\nThe tooltip was edited as shown.\r\nFor the “State” layer, “Country” measure, “Admin3” measure, “Event Interactions and fatalities” sheet and sheet were inserted into the tooltip. \r\nA calculated field “Year Filter” is created and dragged to filter card. \r\nStandardized font to Tableau Book and font color of axis.\r\n4.4 Event Interactions and fatalities Sub Chart\r\nA new calculated field called “Type of Interaction” is created to differentiate whether the event occurred only has one party or two parties. \r\n“Type of Interaction”, “Event Type” and “Sub Event Type” were dragged to rows. \r\n“Sub Event Type” was also dragged to Filters card, to show the Top 5 records. \r\n“Fatalities” and “Number of Events” measure is dragged to Text with the mark card. \r\nStandardize font to Tableau Book and font color of axis.\r\n4.5 Fatalities By Year\r\nThe “Year” measure was dragged to columns and “Fatalities” to rows. \r\n“Sub Event Type” and “Country Filter” were dragged to Filters card, to show the Top 5 records and also dragged to color. \r\nAnother “Fatalities” measure was dragged to rows to create a dual axis chart. The second chart is changed to a “circle” type under the mark card. The axis is also synchronized.\r\n\r\nA reference line is added to show event with highest number of deaths.\r\n\r\nGrid lines were removed. \r\n4.6 Percentage change in Events by Period\r\nNext chart is to be able to show the percentage change on the number of events based on reference year. First, a parameter called “Year Parameter” was created.\r\n\r\nA calculated field called “Value for Year Parameter” is created.\r\n\r\nA calculated field called “% Change vs selected Year” is created.\r\n\r\nTo be able to select the reference year on the chart, a parameter action “Change Year Parameter” is created via Worksheet–>Actions–>Add Action–>Change Parameter.\r\n\r\nThe “Year” measure is dragged to columns and “% change vs selected year” is dragged to rows.\r\n“Event Type” measure is dragged to both color and detail card, and “% change vs selected year” is dragged to label. The label is changed to show the percentage change at the line ends.\r\n\r\n\r\nThe animation of the chart move is changed via Format–> Animations, to 0.80 seconds. \r\nIn order to show the reference year point clearly, a new calculated field “Reference Point” is created. \r\n“Reference Point” measure is dragged to rows and dual axis is selected. The axis was also synchronized and header removed. \r\nA reference line was added to show the reference year as well. \r\nStandardize font to Tableau Book and font color of axis.\r\n4.7 Country Selection Bar\r\nTo create a country selection to be used in dashboard later on, the “Country” measure is dragged to columns and to the text mark card. \r\nThe font size was adjusted to size 12, borders were added via formatting and the chart resized.\r\nA “Country” Parameter was created as shown. \r\nA calculated field “Country Filter” is created. \r\nStandardize font to Tableau Book and font color of axis.\r\n4.8 Dashboard\r\nThe generic desktop size of 1366x768 was chosen for the dashboard size.\r\nTitle of dashboard is added. Title: “Conflicts in Country Events occurred vs Year”.\r\nA vertical box was dragged under the title, with pixel height adjusted to “2” and shaded black to create a line.\r\nThe “Map” sheet and “Percent Change” sheet under “Sheets” is dragged to the dashboard space. The “Country Bar” is dragged below the title.\r\nLegend for event type and number of Events are retained and repositioned below the “Country Bar”.\r\nDashboard actions were added via Dashboard–> Actions–> Add Action. First action to add was the “Change reference year” action choosing of reference year for the % change chart.\r\nSecond action to add was the “Country Parameter” action for choosing selected countries. \r\n“Text” is dragged to the bottom left of the dashboard to include source information: “Source from https://acleddata.com/#/dashboard Data from https://acleddata.com/data-export-tool/”\r\nAnother textbox is created at the bottom right of the dashboard to add the following text: “DataViz Makeover #3 Author: Desmond Lim”\r\nDashboard background color was changed via Dashboard–>Format–> Dashboard Shading \r\n5. Final Visualisation\r\n\r\n6. Main Observations\r\nIn 2020, most of the conflict events occurred Indonesia, Philippines and Myanmar. Laos was the lowest with 3 conflict events that occurred. \r\nSince 2016, “Violence against civilians” and “explosions/remote violence” has been dropping at an increasing rate. While “Riots”, “Protests” and “Strategic development” events has been on a general rising trend. \r\nThere is a huge spike in “Violence against Civilians” in 2016 from 2015 with an increase of 1025%. This is mainly due to events that occurred Calabarzon, Central Luzon and the National Capital region in the Philippines. \r\nThe high number of fatalities in 2017 due to battles in Bangsamoro Autonomous Region of the Philippines, contributing to 1513 deaths of the 2139 deaths in that year. \r\nThe fatalities from battles in Myanmar seemed to follow a four-year cycle, peaking at 2011, 2015 and 2019. \r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-21-dataviz-makeover-3/DataViz3 Pics/Final Viz.png",
    "last_modified": "2021-03-21T02:41:29+08:00",
    "input_file": "dataviz-makeover-3.utf8.md"
  },
  {
    "path": "posts/2021-02-19-dataviz-makeover-2/",
    "title": "DataViz Makeover 2",
    "description": "ISSS608 Visual Analytics and Applications: DataViz Makeover",
    "author": [
      {
        "name": "Desmond Lim",
        "url": {}
      }
    ],
    "date": "2021-02-19",
    "categories": [],
    "contents": "\r\n1. Original Visualisation\r\n\r\n2. Critiques and Suggestions on Original Visualization\r\n2.1 Clarity\r\nCritique\r\nSuggestions\r\nThe country names on the y-axis are sorted differently on both charts. One is sorted alphabetically, while another is sorted on a descending order. It will be difficult for the reader to compare one country on the two charts.\r\nTo sort both charts similarly, either by value or alphabetically.\r\nIt is difficult to visualise the overall sentiment of the respondents through the first 100% stacked bar chart. We are only able to compare the extreme responses.\r\nTo use a divergent stacked bar chart to be able to visualise the positive and negative responses.\r\nThe accuracy of the percentage response is uncertain as there is no information on the sample size it is conducted on in each country.\r\nMake use of confidence interval chart to reflect the margin of error for the responses being given for each score.\r\nThe second chart can only show the response level to those who strongly agree to vaccination but unable show other responses\r\nTo enabling interactivity in the visualisation, i.e. the selecting of different responses will be reflected in the chart.\r\nThe charts does not show what was the question being asked to the public.\r\nTo show what was the question asked to the respondents.\r\n2.2 Aesthetics\r\nCritique\r\nSuggestions\r\nSince the axis title for both charts i.e. “% of Total Record” and “% Strongly agreed” is redundant as what the chart is trying to show has been clearly stated on the chart titles.\r\nTo ensure the chart title and axis title is meaningful and does not repeat.\r\nThe decimal place for the percentage value on the x-axis for the two charts are different. One is whole figure and another is showing to one decimal place.\r\nTo ensure decimal places shown chart values and axis values are standardized.\r\nThe name of the countries on y-axis are not capitalized i.e. first letter not in uppercase.\r\nTo edit the country name .\r\nFor the legend, only 1 and 5 is explained with “Strongly Agree” and “Strongly Disagree”. The rest are only in numbers.\r\nThe scale should be changed to explained the score representation. i.e. Strongly Agree, Agree, Neutral, Disagree, Strongly Disagree.\r\n3. Proposed Visualisation\r\n3.1 Sketch\r\n3.2 Advantages of new visualisation\r\nUsing the above alternative visualisation, it retains the intent of the original charts to reflect a country’s response to the Covid-19 vaccination but made it more intuitive by highlighting the positive responses and negative responses. The survey question being asked is made available to show what was really asked to the public. The tooltip also allow the reader to have within row (country) comparison of the survey response.\r\nThe second chart is able to go in further detail the proportion of each score response and highlight the margin of error for each response.\r\nInteractivity is also introduced to allow the reader to filter amongst the different variables present in the data set and look at survey responses from other survey questions.\r\n4. Data Visualisation Steps\r\n4.1 Data Source\r\nThe data used was obtained from the Imperial College London YouGov Covid 19 Behaviour Tracker Data Hub. The datafiles contain responses from surveys of the general public from about symptoms, testing, self-isolation, social distancing and behaviour from 21 countries.\r\nFor the purpose of the DataViz makeover, the data from the following surveys were used:\r\nSurvey Code\r\nQuestion\r\nvac_1\r\nIf a Covid-19 vaccine were made available to me this week, I would definitely get it\r\nvac2_1\r\nI am worried about getting COVID19\r\nvac2_2\r\nI am worried about potential side effects of a COVID19 vaccine\r\nvac2_3\r\nI believe government health authorities in my country will provide me with an effective COVID19 vaccine\r\nvac2_6\r\nIf I do not get a COVID19 vaccine when it is available, I will regret it\r\nvac_3\r\nIf a Covid-19 vaccine becomes available to me a year from now, I definitely intend to get it\r\nAs only 14 countries were found with the above surveys, only data from these 14 countries were used. The 14 countries are:\r\nCountries\r\n\r\n\r\n\r\n\r\nAustralia\r\nFinland\r\nItaly\r\nNorway\r\nSweden\r\nCanada\r\nFrance\r\nJapan\r\nSingapore\r\nUnited- Kingdom\r\nDenmark\r\nGermany\r\nNetherlands\r\nSouth Korea\r\n\r\n4.2 Data Preparation in Excel\r\nThe “employment_status” variable was found to be classified differently in data from Denmark, Finland, Norway and Sweden. The employment status variable was split into 7 columns based on the original values as shown in below.\r\n\r\nTo obtain the “employment_status” variable, the column headers were changed to the 7 values as shown below\r\n\r\nThe following excel equation “=INDEX($CU\\(1:\\)DA$1,MATCH(”Yes“,CU2:DA2,0))” was used to obtain the employment status. The same method was applied to the Denmark, Finland, Norway and Sweden data set.\r\nThe scores for the different surveys were classified into “1 - Strongly Agree”, “2”, “3”, “4” and “5 -Strongly Disagree”. The string value of “Strongly Agree” and “Strongly Disagree” would affect data in Tableau later on, the values of “1 - Strongly Agree” and “5 -Strongly Disagree”, were replaced with “1” and “5” respectively for all the country data sets used.\r\n4.3 Data Preparation in Tableau\r\nTo prepare the data in Tableau, one of the country’s data set is first dragged into Tableau.\r\n\r\nThe data is then removed as shown. The “New Union” tab is dragged to the interface, generating a “Union” window. The dataset of all the countries are selected and dragged into the “Union” window as shown below. \r\nThe unrelated fields are selected and hidden, leaving behind the following fields.\r\nThe “Table Name” file is split to form a new column and the new field is renamed as “Country”.\r\nIn “Sheet 1”, the data type for the following is changed from “String” to “Number (Whole)”. \r\nConvert the measure “household_children” to dimension and group the number of children above 5 to “5 and more”. Renamed to “No. of Children”. \r\n4.4 Diverging Stacked Bar Chart\r\nCreating Calculated Field\r\nA new calculated field is created from the “Analysis” tab, with the “Create Calculated Field “option.\r\nA calculated field called “Number of Records” is created as shown. \r\nAnother calculated field “Total Count” is created similarly with the below formula. \r\nA new parameter “Survey” is created with settings shown below. The names of the survey were changed to the question of the survey. The parameter is set to “Show Parameter”. \r\nA calculated field named “Select Survey” is created. This field is to allow the switch of surveys between vac_1, vac2_1, vac2_2, vac2_3, vac2_6 and vac_3. The “Show Parameter” option was selected.\r\nThe survey score was edited to show to reflect 1 as “Strongly Agree”, 2 as “Agree”, 3 as “Neutral”, 4 as “Disagree” and 5 as “Strongly Disagree” by choosing to edit “Alias” on “Select Survey”.\r\nAs the value “1” refer to strongly agree, the score is sort in a descending order. \r\nA calculated field “Count Negative” is created as shown below to count the number of negative responses and half the neutral responses. \r\nA calculated field “Total Count Negative” is created. \r\nA calculated field “Percentage” is created.\r\nTo work out where the first position of the Gantt bar, a calculated field “Gantt Start” is created by dividing the negative of “Total Count Negative” by “Total Count”. \r\nA calculated field “Gantt Percent” is created to find the gantt position of the different responses by taking the previous response position and adding in the current response percentage.\r\nCreating Visualization\r\nTo create the chart, the “Country” measure is dragged to the Rows and “Gantt Percent” is dragged to Columns.\r\nThe “Select Survey” measure is dragged to filter. All values are selected other than the ”Null” values.\r\n“Select Survey” is dragged to the Detail card and “Gantt Percent” changed to calculate using “Select Survey”. \r\nThe Mark Type for the chart is changed to “Gantt Bar”, “Select Survey” is dragged to the Colour card and “Percentage” to the Size card.\r\nEdit the colours of the survey score.\r\nFormat the x-axis to show percentage values. Edit the axis for uniform axis range and title.\r\nIn a new sheet i.e. Respondents, drag “Country” to Rows and drag “Number of Records” onto “Text” card and edit text as shown. \r\nTo create a histogram chart as a tooltip. In another new sheet i.e. Histogram, by dragging “Country” and “Select Survey” to Columns and “Percentage” to Rows. \r\nRight click on “Percentage” and select compute using “Select Survey”. \r\n“Percentage” is dragged to the Label card and aligned as shown. \r\nCreate tooltip at the main sheet by clicking on “Tooltip” under the “Marks” card and linking “Respondents” and “Histogram” sheets and include percentage values. \r\nA reference line was added at zero to differentiate the positive and negative segments. \r\nChart title “Question: <Parameters.Survey>” added.\r\nStandardize font to Arial Black and font color of axis.\r\nThe completed visualisation for the diverging stacked bar chart will looked as below. \r\n4.5 Confidence Interval Chart\r\nNext, in order to visualise the uncertainty in the survey results i.e. margin of error. A confidence interval chart is use.\r\nFirst, a parameter “Survey Score” was created to allow which survey response score to be compared.\r\nCreating Calculate Fields\r\nCreate a calculated field, “Select Score”.\r\nAnother calculate field, “Prop Value” is created. This helps to determine the number of respondents choosing a certain score.\r\nNext calculated field to be created is “Prop”, to determine the percentage of respondents choosing a certain score.\r\nA “Standard Error” calculated field is created to obtained the standard error in confidence intervals.\r\nTwo calculated fields are created “Z Value 95%” and “Z Value 99%”. These are multiplier used to calculate the survey results are within 95%/99% of the possible responses. \r\nTwo more fields “Margin of Error 95%” and “Margin of Error 99%” are created. \r\nTwo calculated fields “Lower Limit 95%” and “Lower Limit 99%” for the lower limit for the 95% (99%) error bar. \r\nSimilarly, two calculated fields “Upper Limit 95%” and “Upper Limit 99%” to reflect the upper limit for the 95% (99%) error bar is created. \r\nCreating Visualization\r\nTo create the visualisation, the “Country” measure is dragged to the Rows and “Prop” is dragged to Columns.\r\nSimilar to the previous chart, the “Select Survey” measure is dragged to filter. All values are selected other than the ”Null” values.\r\nThe Mark Type for the chart is changed to “Circle”.\r\nDrag “Measure Values” to Columns, and right click on the Measure Values to create dual axis. Right click on the lower x-axis and choose “Synchronize Axis”.\r\nFilter the “Measure Names” by right-clicking it on the Filters card and retain “Lower Limit 95%”, “Lower Limit 99%”, “Upper Limit 95%” and “Upper Limit 99%”. \r\nUnder “Measure Value” in the Mark card, change the Mark type to “Lines” and drag “Measure Names” to “Path”.\r\nDrag “Measure Names” to “Color”, click on “Color” and edit the color palette to match the confidence intervals.\r\nHide the top header by unchecking “Show Header”.\r\nFormat the x-axis to show percentage values. Edit the axis for uniform axis range and title.\r\nThe chart tile “Confidence Level of Response for <Parameters.Survey Score>” is added to include show the survey score parameter.\r\nStandardize font to Arial Black and font color of axis.\r\nThe completed visualisation for the confidence interval chart will looked as below.\r\n4.6 Filters\r\nThe “Gender” dimensions is dragged to the Filter card and set to “Show Filter”. \r\nThe same were done to “Employment Status”, “Household Size” and “No. of Children”.\r\nAll the filters were set to apply to all worksheets using the same data source and a single value dropdown. \r\nThe “Age” measure was dragged to filter and set to filter by range. \r\n4.7 Dashboard\r\nTitle of dashboard is added. Title: “How about a Vaccine for you? Survey on Covid-19 Vaccine.”\r\nCommentary is added by dragging “Text” from “Objects” to the bottom of the title. Commentary states “Responses from the general public in 14 countries, given towards questions asked regarding the Covid-19 vaccine.”\r\nThe “Diverging stacked Bar” sheet and “CI Chart” sheet under “Sheets” is dragged to the dashboard space. All filters with survey score legend are retained.\r\n“Text” is dragged to the bottom left of the dashboard to include source information: “Source from: https://github.com/YouGov-Data/covid-19-tracker Data from:https://github.com/YouGov-Data/covid-19-tracker/tree/master/data”\r\nAnother textbox is created at the bottom right of the dashboard to add the following text: “DataViz Makeover #2 Author: Desmond Lim”\r\n5. Final Visualisation\r\n\r\n6. Main Observations\r\nMost countries show general positive sentiment towards taking the Covid-19 vaccine if made available, as shown in the chart. i.e. Positive sentiments higher than negative sentiments. Only France out of the 14 countries shows a negative sentiment response to the vaccine. \r\nFor VAC_1, there is a larger margin of error responses for Netherlands, Japan and South Korea compared to the other countries. This is due to the smaller sample size of respondents from the three countries. Netherlands with 10,899, Japan with 10,887 respondents and South Korea with 9,807 respondents. The next lowest country is Canada with 18,780 respondents, which is almost two times South Korea’s. \r\nComparing VAC_1 with VAC_3, where VAC_3 is about willing to take the vaccine when made available 1 year later, there is a significant increase from the public response from various countries where the public strongly agrees with the statement, i.e. France from 21.9% to 35.3%, Singapore from 18.1% to 27.4%. This shows a portion of the public still doubts the efficacy of the Covid-19 vaccine at this stage. \r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-19-dataviz-makeover-2/DataViz 2 Pics/Final Viz.png",
    "last_modified": "2021-02-19T07:00:53+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-27-dataviz-makeover-1/",
    "title": "DataViz Makeover 1",
    "description": "ISSS608 Visual Analytics and Applications: DataViz Makeover",
    "author": [
      {
        "name": "Desmond Lim",
        "url": {}
      }
    ],
    "date": "2021-01-27",
    "categories": [],
    "contents": "\r\n1. Critiques and Suggestions on Current Visualisation\r\nClarity\r\nCritiques\r\nSuggestions\r\n1) Information in the lead-in paragraph could not be visualized/interpreted from the chart. For example, it stated the share of labour force aged 25 to 54 declined from 75% to 67%. That could not be interpreted from the chart, as the population are grouped in 5-year brackets.\r\nThe dashboard title and lead-in to be able to relate and provide an intuitive understanding to the chart visualisation.\r\n2) The visualisation only depicts the comparison statistics from 2009 and 2019. It lacks the information on the changes between 2009 and 2019.\r\nThe chart visualisation will incorporate the data from 2009 to 2019 to gain more insights to the change in resident labour population over the years.\r\n3) It is not clear whether x-axis labels i.e. 15-19,is categorical or continuous. There is no x-axis title to explain the axis value. Lack of a y-axis and gridlines to provide a gauge for the values.\r\nTo ensure accurate x and y-axis labels with axis title to describe the axis.\r\n4) The median age reference lines used might not be accurately reflecting the chart as the x-axis of “40-44” might be a categorical data.\r\nTo use other statistical values to provide insights to the labour force participation.\r\nAesthetics\r\nCritiques\r\nSuggestions\r\n1) The x-axis labels are not aligned to the tick marks but in between the tick marks.\r\nIncorporate proper axis labelling and aligning.\r\n2) Poor colour coding. The colour of the “June 2009” line is too close to the background colour.\r\nProper colour but non-excessive colour coding to highlight necessary information.\r\n3) Poor spacing between the chart axis and the table.\r\nInstead of using a table, proper axis will be in place to show the values in the visualisation\r\n2. Proposed Visualisation Design\r\n Using the above alternative visualisation, it retains the intent of the lead in paragraph which is to be able to compare the labour force participation rate directly with actual resident population in the workforce through a dual axis visualisation.\r\nIt also follows the re-grouping of the age groups into in the lead-in paragraph by classifying into 3 groups “Age 15-24”, “Age 25-54” and “Age 55 & over”.\r\n3. Tableau Visualisation Steps\r\nData Preparation in Excel\r\nS/N\r\nArea\r\nAction\r\n1\r\nRemove irrelevant data\r\nRemoved one row of data under “Total” from excel data file “mrsd_2019LabourForce_T7”.\r\n2\r\nExtract relevant data\r\nExtracted fives rows of data under “15 -24”, “25 -54”, “55 -65” and “65 & over” from excel data file “mrsd_2019LabourForce_T5”.\r\nChart Preparation in Tableau\r\nS/N\r\nArea\r\nAction\r\n1\r\nImport data (Excel) into Tableau\r\n- Connection was created with “mrsd_2019LabourForce_T7”. - Using sheets “T7_T” from the data, a column containing “null” values was hidden. - The columns for the individual years, were highlighted and pivoted to transpose the data.  - The new column was renamed and data type changed from “String” to “Year”.  - “Age (Years)” renamed to “Age Group (Years)”  - Another data source “mrsd_2019LabourForce_T5” was added.  - Same steps were taken to transpose the “Year” columns and to change data type.\r\n2\r\nGrouping the Age Groups\r\n- In Sheet 1, the “Age Group (Years)” table is further grouped through the “Create”, “Group” function as shown. - The “Age Group” was further grouped into 4 main groups namely “15 -24”, “25 -54”, “55 -65” and “65 & over”.  - Creating a new Table “Age Group (Years) II”.\r\n3\r\nCreating first chart\r\n- The first chart shows the resident labour force in each of the age group. - The “Year” measure was dragged to column and the “Population” measure was dragged to Rows. The mark was change to “Line”. - To view the labour participation rate, “Quick Table Calculation” was used to calculate “Percent of Total” and computed using “Table (down)”.- “Sum(Population)” was Ctrl+ Drag to Label. “Line Ends” option was selected.- The y-axis was renamed to “Labour Force by Age Group”  - “Sheet 1” was renamed as “Workforce”.\r\n4\r\nCreating second chart\r\n- The first chart shows the resident labour force participation rate in each of the age group. - A new calculation field “LFPR%” was created with the formula “[LFPR]/100”. This is in order to display the data in percentage format. - The “Year” measure was dragged to column and the “LFPR%” measure was dragged to Rows. - “LFPR%” was dragged to Label. “Line Ends” option was selected. - The y-axis was renamed to “Labour Force Participation Rate”. Y-axis formatted to show percentage. - “Sheet 2” was renamed as “LFPR”.\r\n5\r\nCreating of dashboard And formatting\r\n- Drag “Workforce” and “LFPR” sheet into dashboard. - Drag Text bar to create dashboard title and data source. - Axis of both charts were edited for them to align.\r\n4. Final Visualisation\r\n\r\n5. Insights\r\nThe labour force participation rate for the elderly (55 years old and above) has increased significantly over the years. From 2009 to 2019, the LFPR for the 55 to 64 age group increased from 60.65 to 69.9% and 17.2% to 28.7% for the 64 and above age group. Correspondent changes were seen in the elderly proportion in the labour force with an increase in about 5% for the 55 to 64 age group and about 4% in the 65 and above age group.\r\n\r\nAlthough the labour force participation rate for the main workforce (25-54 years) has increased to 88.3% in 2019 from 84.5% in 2009. A significant drop was seen in the age group’s proportion in the labour force from 75.35% to 67.44%. This was due to the aging of the main force and transitioning into the elderly work force (55 and over) over the past 10 years.\r\n 3. The proportion of the youth (15-24 years) in the labour force is stable with a drop of about 1% from 8.97% (Year 2009) to 7.95% (Year 2019). However, there is an increase of labour force participation rate from 35.6% to 38.3%.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-27-dataviz-makeover-1/DataViz1 Pics/Dataviz1 Pic 16 Dashboard.png",
    "last_modified": "2021-01-28T02:44:33+08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-04-my-first-post/",
    "title": "My First Post",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Desmond Lim",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-01-04",
    "categories": [],
    "contents": "\r\n1.0 Overview\r\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coeficient of 0.0 shows no linear relationship between the two variables.\r\nWhen multivariate data are used, the correlation coeficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\r\nThere are three broad reasons for computing a correlation matrix.\r\nTo reveal the relationship between highdimensional variables pairwisely.\r\nTo input into other analyses. For example, people commonly use correlation matrixes as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\r\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\r\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\r\nRendering the value of a correlation to depict its sign and magnitude, and\r\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\r\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R Lastly, you will learn how to create an interactive correlation matrix using plotly R. .\r\n2.0 Installing and Launching R Packages\r\nBefore you get started, you are required:\r\nto start a new R project, and\r\nto create a new R Markdown document.\r\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\r\n\r\n\r\npackages = c('ggpubr', 'tidyverse')\r\n\r\nfor(p in packages){library\r\n  if(!require(p, character.only = T)){\r\n    install.packages(p)\r\n  }\r\n  library(p, character.only = T)\r\n}\r\n\r\n\r\n\r\n3.0 Importing and Preparing The Data Set\r\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\r\n3.1 Importing Data\r\nFirst, let us import the data into R by using read_csv() of readr package.\r\n\r\n\r\nwine <- read_csv(\"data/wine_quality.csv\")\r\n\r\n\r\n\r\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type.\r\n4.0 Univariate EDA with Histogram\r\nIn the figure below, multiple histograms are plottted to reveal the distribution of the selected variables in the wine quality data sets.\r\n\r\n\r\n\r\nThe code chunks used to create the data visualisation consists of two main parts. First, we will create the individual histograms using the code chunk below.\r\n\r\n\r\nfa <- ggplot(data=wine, aes(x= `fixed acidity`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nva <- ggplot(data=wine, aes(x= `volatile acidity`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nca <- ggplot(data=wine, aes(x= `citric acid`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nrs <- ggplot(data=wine, aes(x= `residual sugar`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nch <- ggplot(data=wine, aes(x= `chlorides`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nfSO2 <- ggplot(data=wine, aes(x= `free sulfur dioxide`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\ntSO2 <- ggplot(data=wine, aes(x= `total sulfur dioxide`)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\ndensity <- ggplot(data=wine, aes(x= density)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\npH <- ggplot(data=wine, aes(x= pH)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nsulphates <- ggplot(data=wine, aes(x= sulphates)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\nalcohol <- ggplot(data=wine, aes(x= alcohol)) +\r\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\r\n\r\n\r\n\r\nNext, the ggarrange function of ggpur package is used to group these histograms together.\r\n\r\n\r\nggarrange(fa, va, ca, rs, ch, fSO2, tSO2, density, pH, sulphates, alcohol, \r\n          ncol = 4, nrow = 3)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-04-my-first-post/my-first-post_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-01-06T18:42:12+08:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Idea",
    "description": "Welcome to our new blog, Idea. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Dasimon Lim",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2021-01-04",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-04T20:59:52+08:00",
    "input_file": {}
  }
]
